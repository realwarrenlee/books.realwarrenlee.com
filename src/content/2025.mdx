export const frontmatter = {
  title: "2025",
  date: "2025-12-31",
  category: "Reflection",
  description: "Reflecting on my journey in National Service and University.",
  slug: "2025"
};

import {
  Table,
  TableBody,
  TableCell,
  TableHead,
  TableHeader,
  TableRow,
  TableCaption,
} from "@/components/ui/table";
import { TableHeadWithWidth, TableCellWithWidth } from "@/components/TableWithWidth";

### A Fresh Start

Over the past few years, the report has gotten lengthy and veered too far from its original point. From AI trends to startup ideas among many other things, I have failed to even understand why I write it and what its purpose is. Moreover, there is much AI slop in it, and I feel it is time to stop. During those reports, I relied heavily on Claude to help me write. And it is destroying my thinking. 

Writing is thinking. It is supposed to be messy, full of dead ends and revisions. But I sanitized it with Claude, outsourcing not just the polish but the thinking itself. And the fact that Dario Amodei's [internal communication style](https://x.com/tbpn/status/1993088517497651559) produces a compendium of essays without the use of Claude is telling. While I do not intend to stop using Claude, I will definitely no longer push the burden of writing to it.

On the format, I do think [vibe coding](https://x.com/karpathy/status/1886192184808149383) has come a long way, though it's not even a year since vibe coding came out. Nevertheless, I think the website version is better than using a PDF because it is more interactive, accessible, and has a much better user interface. Going forward, I will be aiming for less sprawl, more focus.

### Company Overview

Nebius Group builds vertically integrated AI infrastructure designed to accelerate AI innovation at scale. The company operates large-scale GPU clusters deployed across Europe and the US through a full-stack cloud platform that combines the scale, flexibility, and reliability of a hyperscaler with the power and performance of a supercomputer.

The company's infrastructure is purpose-built for the demands of modern AI development, providing vast amounts of compute power with optimized software and hardware to support AI as a general-purpose technology.


### Investment Thesis

**AI’s next bottleneck isn’t data or algorithms. It’s compute.**

Compute demand for AI is expanding exponentially, but traditional hyperscalers cannot keep pace. AWS faces internal bureaucracy and the limited capabilities of its custom Trainium chips. Azure is expanding capacity but still relies on partnerships with CoreWeave and Nebius to fill GPU infrastructure gaps. GCP prioritizes internal DeepMind research, diverting compute toward proprietary models rather than external customers. This structural shortage has created an opening for GPU-focused "neoclouds" which represents a pure-play bet on this infrastructure layer.

The rise of generative AI has triggered unprecedented compute demand for both training and inference. OpenAI CEO Sam Altman has stated that global compute needs are still "severely underestimated." ChatGPT's trajectory toward one billion users demonstrates the scale of adoption driving this demand. Each model generation requires 10× more compute than the last. Frontier models now target clusters exceeding 100,000 GPUs. Meanwhile, inference workloads drive persistent, recurring demand as AI moves from research to production at scale.

This has opened the door for neoclouds like CoreWeave, Nebius, and IREN. These companies specialize in dense GPU clusters optimized for AI workloads rather than the general-purpose infrastructure hyperscalers built for web services and databases. This focus enables faster deployment cycles, higher GPU utilization, and direct relationships with AI labs. CoreWeave and IREN pivoted from crypto mining to AI infrastructure, while Nebius was spun out from Yandex specifically to build GPU supercomputers from the ground up. Even Oracle is taking on massive debt to finance an AI infrastructure buildout that will define its next decade.

Recent consolidation through acqui-hires—Meta acquiring the Scale AI team, Microsoft absorbing Inflection AI—might suggest weakening startup demand. I see the opposite. Larger players are doubling down, and their compute requirements dwarf what startups consumed. Every training run, every fine-tuning session, every production deployment requires GPU cycles. The bigger players get, the more compute they need.

Nebius offers leveraged exposure to the AI infrastructure buildout. It is capital-intensive, early-stage, and carries execution risk. However, it aligns with the most durable secular trend in technology: exponential growth in compute demand. Meta CEO Mark Zuckerberg said he would rather "misspend a couple hundred billion" on AI than risk missing it. There are three layers in AI: models, chips, and infrastructure. With most AI labs private, only two layers are accessible to public market investors: chips (NVIDIA, Broadcom) and infrastructure (datacenters). Given the scale of semiconductor companies and their limited percentage upside, I choose to bet on AI infrastructure companies as many still valued under $100 billion.

### Products & Services

Nebius operates as a full-stack AI infrastructure provider, offering two core products: Nebius AI Cloud and Nebius AI Studio. 

AI Cloud delivers GPU-optimized infrastructure for AI training and inference. This includes compute, storage, and high-bandwidth networking resources purpose-built for large-scale workloads.

AI Studio is a developer platform built on top of that infrastructure. It allows users to run, fine-tune, and deploy open-source AI models through APIs or an interactive interface. 

In practical terms, Nebius sells access to NVIDIA GPUs—the core bottleneck resource in AI. The company currently offers L40S, H100, and H200 GPUs, with next-generation Blackwell architecture (GB200 NVL72 / GB300 NVL72) available for pre-order. 

<Table>
  <TableHeader>
    <TableRow>
      <TableHeadWithWidth width="20%">GPU Model</TableHeadWithWidth>
      <TableHeadWithWidth width="40%">On-demand Price</TableHeadWithWidth>
      <TableHeadWithWidth width="40%">Commitment Price</TableHeadWithWidth>
    </TableRow>
  </TableHeader>
  <TableBody>
    <TableRow>
      <TableCellWithWidth width="20%" className="font-medium">H100</TableCellWithWidth>
      <TableCellWithWidth width="40%">$2.95 per GPU-hour</TableCellWithWidth>
      <TableCellWithWidth width="40%">$2.00 per GPU-hour</TableCellWithWidth>
    </TableRow>
    <TableRow>
      <TableCellWithWidth width="20%" className="font-medium">H200</TableCellWithWidth>
      <TableCellWithWidth width="40%">$3.50 per GPU-hour</TableCellWithWidth>
      <TableCellWithWidth width="40%">$2.30 per GPU-hour</TableCellWithWidth>
    </TableRow>
  </TableBody>
</Table>

By offering flexible pricing to accommodate different customer needs, Nebius positions itself competitively within the GPU cloud market. On-demand pricing offers flexibility for experimentation and variable workloads, while commitment contracts deliver meaningful discounts for sustained usage which are critical for large-scale training runs that can span weeks or months. 

The combination of competitive pricing, early access to frontier hardware, and a full-stack platform gives Nebius the operational flexibility to serve both emerging AI startups and established enterprises scaling production workloads.

### Business Model

Nebius operates a high-growth, high-capex model designed to capture accelerating demand for AI compute infrastructure. Its go-to-market strategy targets both the largest AI "whales" and the long tail of AI-native startups and enterprises.

Nebius generates revenue through two complementary platforms that balance scale, predictability, and margin: Long-Term Commitment Platform and Consumption-Based Platform.

Long-Term Commitment Platform focuses on hyperscalers and leading AI labs that require massive, dedicated GPU capacity. Nebius signs multi-year, multi-billion-dollar contracts that secure predictable, recurring revenue with high visibility. In September 2025, Nebius signed a five-year, $19.4 billion agreement with Microsoft.

Under this model, Nebius provides reserved GPU clusters with guaranteed availability and performance. These contracts lock in utilization and act as collateral for raising low-cost debt financing. The debt is then reinvested into GPU procurement and data center expansion, creating a capital-efficient growth flywheel that compounds both capacity and revenue backlog.

Consumption-Based Platform powers Nebius AI Cloud and AI Studio, targeting startups and enterprises that prioritize flexibility over long-term commitments. Customers are charged on a per-GPU-hour basis, with discounts available for 1 to 3 year commitments.

While smaller in average contract size, this segment delivers higher margins, particularly through AI Studio which layers software services (fine-tuning, deployment, inference APIs) on top of bare metal infrastructure. This software abstraction captures more value per compute dollar and reduces customer friction.

The consumption-based model also serves as a customer acquisition funnel. Startups that begin on flexible pricing can graduate into commitment contracts as their compute needs scale which creates organic expansion revenue.

Nebius's business model is reinforced and dependent on two critical relationships: Microsoft and NVIDIA.

- **Microsoft** – Nebius's flagship infrastructure customer, anchoring its long-term revenue backlog and providing demand visibility that enables aggressive capacity expansion.
- **NVIDIA** - Nebius is a “Reference Platform Cloud Partner” of NVIDIA, granting it priority access to NVIDIA’s latest accelerators, ensuring competitive GPU supply at scale. NVIDIA’s equity stake aligns incentives, positioning Nebius as a preferred deployment partner for cutting-edge AI hardware.

These partnerships create a virtuous cycle: Microsoft's capacity commitments de-risk capital deployment, while NVIDIA's preferential access ensures Nebius can fulfill those commitments with frontier hardware.

Beyond cloud infrastructure, Nebius Group owns or operates several complementary technology assets that expand its ecosystem reach: ClickHouse, Avride, TripleTen, and Toloka.

- **ClickHouse** - A high-performance, open-source analytical database integrated into Nebius's data infrastructure stack.
- **Avride** - Autonomous driving systems leveraging Nebius compute for training and simulation workloads.
- **TripleTen** - A reskilling platform training the next generation of AI engineers, creating a talent pipeline for the broader ecosystem.
- **Toloka** - A data labeling and model fine-tuning platform that supports AI development workflows.